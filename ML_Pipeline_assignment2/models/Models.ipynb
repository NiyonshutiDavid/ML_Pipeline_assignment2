{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "##Multi-Modal Predictive Modeling: Voice, Facial & Product Recommendation Systems\n",
        "This notebook presents the development of three machine learning models :\n",
        "\n",
        "**Facial Recognition Model** . Uses engineered image features to identify customers based on facial attributes.\n",
        "\n",
        "**Voiceprint Verification Model** . Verifies users through voice embedding features.\n",
        "\n",
        "**Product Recommendation Model** . Predicts product categories based on transaction and engagement data using supervised learning.\n",
        "All models are evaluated using standard metrics including Accuracy, F1-Score, and Loss etc."
      ],
      "metadata": {
        "id": "o_BwAR66tSeA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Facial Recognition Model\n"
      ],
      "metadata": {
        "id": "rEkfGLHTEUG8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3iVLeJBBQN6",
        "outputId": "e5c6f745-6054-4284-cc91-eeb2e65f02f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  member expression augmentation        feat_0    feat_1    feat_2    feat_3  \\\n",
            "0  david    neutral     original  3.908344e-06  0.000261  0.001713  0.003812   \n",
            "1  david    neutral      rotated  3.908344e-06  0.000261  0.001713  0.003812   \n",
            "2  david    neutral      flipped  3.908344e-06  0.000261  0.001713  0.003812   \n",
            "3  david    neutral    grayscale  1.395837e-07  0.000083  0.002578  0.008346   \n",
            "4  david      smile     original  4.299178e-05  0.000831  0.002449  0.008304   \n",
            "\n",
            "     feat_4    feat_5    feat_6  ...   feat_86   feat_87   feat_88   feat_89  \\\n",
            "0  0.015205  0.027483  0.018210  ...  0.001355  0.001092  0.000992  0.000874   \n",
            "1  0.015205  0.027483  0.018210  ...  0.001355  0.001092  0.000992  0.000874   \n",
            "2  0.015205  0.027483  0.018210  ...  0.001355  0.001092  0.000992  0.000874   \n",
            "3  0.024398  0.074433  0.068416  ...       NaN       NaN       NaN       NaN   \n",
            "4  0.027262  0.021193  0.010250  ...  0.001102  0.001067  0.000954  0.000813   \n",
            "\n",
            "    feat_90   feat_91   feat_92   feat_93   feat_94   feat_95  \n",
            "0  0.000737  0.000729  0.001071  0.003056  0.007471  0.180818  \n",
            "1  0.000737  0.000729  0.001071  0.003056  0.007471  0.180818  \n",
            "2  0.000737  0.000729  0.001071  0.003056  0.007471  0.180818  \n",
            "3       NaN       NaN       NaN       NaN       NaN       NaN  \n",
            "4  0.000981  0.001821  0.004935  0.008417  0.014734  0.165581  \n",
            "\n",
            "[5 rows x 99 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 60 entries, 0 to 59\n",
            "Data columns (total 99 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   member        60 non-null     object \n",
            " 1   expression    60 non-null     object \n",
            " 2   augmentation  60 non-null     object \n",
            " 3   feat_0        60 non-null     float64\n",
            " 4   feat_1        60 non-null     float64\n",
            " 5   feat_2        60 non-null     float64\n",
            " 6   feat_3        60 non-null     float64\n",
            " 7   feat_4        60 non-null     float64\n",
            " 8   feat_5        60 non-null     float64\n",
            " 9   feat_6        60 non-null     float64\n",
            " 10  feat_7        60 non-null     float64\n",
            " 11  feat_8        60 non-null     float64\n",
            " 12  feat_9        60 non-null     float64\n",
            " 13  feat_10       60 non-null     float64\n",
            " 14  feat_11       60 non-null     float64\n",
            " 15  feat_12       60 non-null     float64\n",
            " 16  feat_13       60 non-null     float64\n",
            " 17  feat_14       60 non-null     float64\n",
            " 18  feat_15       60 non-null     float64\n",
            " 19  feat_16       60 non-null     float64\n",
            " 20  feat_17       60 non-null     float64\n",
            " 21  feat_18       60 non-null     float64\n",
            " 22  feat_19       60 non-null     float64\n",
            " 23  feat_20       60 non-null     float64\n",
            " 24  feat_21       60 non-null     float64\n",
            " 25  feat_22       60 non-null     float64\n",
            " 26  feat_23       60 non-null     float64\n",
            " 27  feat_24       60 non-null     float64\n",
            " 28  feat_25       60 non-null     float64\n",
            " 29  feat_26       60 non-null     float64\n",
            " 30  feat_27       60 non-null     float64\n",
            " 31  feat_28       60 non-null     float64\n",
            " 32  feat_29       60 non-null     float64\n",
            " 33  feat_30       60 non-null     float64\n",
            " 34  feat_31       60 non-null     float64\n",
            " 35  feat_32       45 non-null     float64\n",
            " 36  feat_33       45 non-null     float64\n",
            " 37  feat_34       45 non-null     float64\n",
            " 38  feat_35       45 non-null     float64\n",
            " 39  feat_36       45 non-null     float64\n",
            " 40  feat_37       45 non-null     float64\n",
            " 41  feat_38       45 non-null     float64\n",
            " 42  feat_39       45 non-null     float64\n",
            " 43  feat_40       45 non-null     float64\n",
            " 44  feat_41       45 non-null     float64\n",
            " 45  feat_42       45 non-null     float64\n",
            " 46  feat_43       45 non-null     float64\n",
            " 47  feat_44       45 non-null     float64\n",
            " 48  feat_45       45 non-null     float64\n",
            " 49  feat_46       45 non-null     float64\n",
            " 50  feat_47       45 non-null     float64\n",
            " 51  feat_48       45 non-null     float64\n",
            " 52  feat_49       45 non-null     float64\n",
            " 53  feat_50       45 non-null     float64\n",
            " 54  feat_51       45 non-null     float64\n",
            " 55  feat_52       45 non-null     float64\n",
            " 56  feat_53       45 non-null     float64\n",
            " 57  feat_54       45 non-null     float64\n",
            " 58  feat_55       45 non-null     float64\n",
            " 59  feat_56       45 non-null     float64\n",
            " 60  feat_57       45 non-null     float64\n",
            " 61  feat_58       45 non-null     float64\n",
            " 62  feat_59       45 non-null     float64\n",
            " 63  feat_60       45 non-null     float64\n",
            " 64  feat_61       45 non-null     float64\n",
            " 65  feat_62       45 non-null     float64\n",
            " 66  feat_63       45 non-null     float64\n",
            " 67  feat_64       45 non-null     float64\n",
            " 68  feat_65       45 non-null     float64\n",
            " 69  feat_66       45 non-null     float64\n",
            " 70  feat_67       45 non-null     float64\n",
            " 71  feat_68       45 non-null     float64\n",
            " 72  feat_69       45 non-null     float64\n",
            " 73  feat_70       45 non-null     float64\n",
            " 74  feat_71       45 non-null     float64\n",
            " 75  feat_72       45 non-null     float64\n",
            " 76  feat_73       45 non-null     float64\n",
            " 77  feat_74       45 non-null     float64\n",
            " 78  feat_75       45 non-null     float64\n",
            " 79  feat_76       45 non-null     float64\n",
            " 80  feat_77       45 non-null     float64\n",
            " 81  feat_78       45 non-null     float64\n",
            " 82  feat_79       45 non-null     float64\n",
            " 83  feat_80       45 non-null     float64\n",
            " 84  feat_81       45 non-null     float64\n",
            " 85  feat_82       45 non-null     float64\n",
            " 86  feat_83       45 non-null     float64\n",
            " 87  feat_84       45 non-null     float64\n",
            " 88  feat_85       45 non-null     float64\n",
            " 89  feat_86       45 non-null     float64\n",
            " 90  feat_87       45 non-null     float64\n",
            " 91  feat_88       45 non-null     float64\n",
            " 92  feat_89       45 non-null     float64\n",
            " 93  feat_90       45 non-null     float64\n",
            " 94  feat_91       45 non-null     float64\n",
            " 95  feat_92       45 non-null     float64\n",
            " 96  feat_93       45 non-null     float64\n",
            " 97  feat_94       45 non-null     float64\n",
            " 98  feat_95       45 non-null     float64\n",
            "dtypes: float64(96), object(3)\n",
            "memory usage: 46.5+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "#Import the necessary Python libraries for Facial Recognition\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
        "import joblib\n",
        "\n",
        "# Load the image features dataset into the notebook\n",
        "df = pd.read_csv('image_features.csv')\n",
        "\n",
        "# Display the first five rows\n",
        "print(df.head())\n",
        "\n",
        "# Display column information\n",
        "print(df.info())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fill missing values in feature columns with 0.0\n",
        "feature_cols = [col for col in df.columns if col.startswith('feat_')]\n",
        "df[feature_cols] = df[feature_cols].fillna(0.0)\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df[feature_cols]\n",
        "y = df['member']"
      ],
      "metadata": {
        "id": "bkR2VHEFDSpa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train a RandomForestClassifier model\n",
        "model = RandomForestClassifier(random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_proba = model.predict_proba(X_test)\n"
      ],
      "metadata": {
        "id": "yIp9mu5MDYVz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred, average='macro')\n",
        "loss = log_loss(y_test, y_pred_proba)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"F1 Score (macro): {f1:.4f}\")\n",
        "print(f\"Log Loss: {loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bSwzJhWDcWf",
        "outputId": "58353bd6-bf58-4abf-fad4-0c12f09fdcd5"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n",
            "F1 Score (macro): 1.0000\n",
            "Log Loss: 0.0971\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model 'facial_recognition_model.joblib)\n",
        "joblib.dump(model, 'facial_recognition_model.joblib')\n",
        "\n",
        "print(\" The facial recognition model saved as 'facial_recognition_model.joblib'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VgHa6ywLDts9",
        "outputId": "da162395-97fa-4c39-87c8-64fe54cecb6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " The facial recognition model saved as 'facial_recognition_model.joblib'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Voice print Recognition model"
      ],
      "metadata": {
        "id": "3tFDDo5ktpjL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the audio features dataset for the voice print recog model\n",
        "df_audio = pd.read_csv('audio_features.csv')\n",
        "\n",
        "# View the first few rows\n",
        "print(\"Audio Data Head:\")\n",
        "print(df_audio.head())\n",
        "\n",
        "# View  column information\n",
        "print(\"\\nAudio Data Info:\")\n",
        "print(df_audio.info())"
      ],
      "metadata": {
        "id": "70Vtc8MQtt8r",
        "outputId": "0affa3cf-a5e8-414d-ec28-744f0f4c2b2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Audio Data Head:\n",
            "  member   sample augmentation    energy       rolloff      mfcc_0  \\\n",
            "0  david  approve     original  0.001125   5532.897534 -470.388733   \n",
            "1  david  approve        pitch  0.000563   6390.997024 -496.560272   \n",
            "2  david  approve      stretch  0.000520   5738.483481 -502.090332   \n",
            "3  david  approve        noise  0.001149  18446.853741 -315.086473   \n",
            "4  david  confirm     original  0.001037   3318.497475 -451.448822   \n",
            "\n",
            "       mfcc_1     mfcc_2     mfcc_3    mfcc_4     mfcc_5    mfcc_6    mfcc_7  \\\n",
            "0  115.434631  10.793375  36.576359  5.174695  19.042986  2.409958  6.798976   \n",
            "1  107.548767  14.688319  32.677586  4.130080  18.449661 -0.713317  9.971756   \n",
            "2  112.294426  10.916822  36.193268  4.142584  18.785419  2.008073  6.771557   \n",
            "3   26.225565  15.723828  18.246023  7.690150  10.177798  6.418136  4.844470   \n",
            "4  155.922226  17.962776  33.061432  4.993365  15.411249  0.774826  5.132216   \n",
            "\n",
            "     mfcc_8    mfcc_9   mfcc_10   mfcc_11   mfcc_12  \n",
            "0  7.123512  0.306631  5.249000 -3.113587  1.810558  \n",
            "1  2.471186  2.218746  2.638993 -2.400248  4.762332  \n",
            "2  6.970181  0.301082  6.034530 -3.361459  1.591592  \n",
            "3  5.583466  2.479509  2.543774  0.516795  1.073807  \n",
            "4  5.629819 -5.929314  1.279346 -5.014614  2.280145  \n",
            "\n",
            "Audio Data Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 40 entries, 0 to 39\n",
            "Data columns (total 18 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   member        40 non-null     object \n",
            " 1   sample        40 non-null     object \n",
            " 2   augmentation  40 non-null     object \n",
            " 3   energy        40 non-null     float64\n",
            " 4   rolloff       40 non-null     float64\n",
            " 5   mfcc_0        40 non-null     float64\n",
            " 6   mfcc_1        40 non-null     float64\n",
            " 7   mfcc_2        40 non-null     float64\n",
            " 8   mfcc_3        40 non-null     float64\n",
            " 9   mfcc_4        40 non-null     float64\n",
            " 10  mfcc_5        40 non-null     float64\n",
            " 11  mfcc_6        40 non-null     float64\n",
            " 12  mfcc_7        40 non-null     float64\n",
            " 13  mfcc_8        40 non-null     float64\n",
            " 14  mfcc_9        40 non-null     float64\n",
            " 15  mfcc_10       40 non-null     float64\n",
            " 16  mfcc_11       40 non-null     float64\n",
            " 17  mfcc_12       40 non-null     float64\n",
            "dtypes: float64(15), object(3)\n",
            "memory usage: 5.8+ KB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Select feature columns(assumption: 'energy', 'rolloff', and 'mfcc_' are the feature columns)\n",
        "#Exclude 'member', 'segmentation' and 'sample' columns\n",
        "audio_feature_cols = [col for col in df_audio.columns if col not in ['member', 'sample', 'augmentation']]"
      ],
      "metadata": {
        "id": "yEz7mzp5tzsn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fill any missing values if found ( based on .info() results)\n",
        "df_audio[audio_feature_cols] = df_audio[audio_feature_cols].fillna(0.0)\n"
      ],
      "metadata": {
        "id": "cnp1Y1o5tzTF"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define the features(X)  and target(Y) variables\n",
        "X_audio = df_audio[audio_feature_cols]\n",
        "y_audio = df_audio['member']\n"
      ],
      "metadata": {
        "id": "6wuWHS0NuGNS"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into training and testing sets\n",
        "X_audio_train, X_audio_test, y_audio_train, y_audio_test = train_test_split(\n",
        "    X_audio, y_audio, test_size=0.3, random_state=42, stratify=y_audio\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "V1J0HDWCuV_b"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a RandomForestClassifier model for voiceprint verification\n",
        "voice_model = RandomForestClassifier(random_state=42)\n",
        "voice_model.fit(X_audio_train, y_audio_train)\n",
        "\n",
        "# Make predictions\n",
        "y_audio_pred = voice_model.predict(X_audio_test)\n",
        "y_audio_pred_proba = voice_model.predict_proba(X_audio_test)\n"
      ],
      "metadata": {
        "id": "va1GlwLduaMK"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "audio_accuracy = accuracy_score(y_audio_test, y_audio_pred)\n",
        "audio_f1 = f1_score(y_audio_test, y_audio_pred, average='macro')\n",
        "audio_loss = log_loss(y_audio_test, y_audio_pred_proba)\n",
        "\n",
        "print(f\"\\nVoiceprint Verification Model Performance:\")\n",
        "print(f\"Accuracy: {audio_accuracy:.4f}\")\n",
        "print(f\"F1 Score (macro): {audio_f1:.4f}\")\n",
        "print(f\"Log Loss: {audio_loss:.4f}\")\n",
        "\n",
        "# Save the trained voiceprint verification model\n",
        "joblib.dump(voice_model, 'voiceprint_verification_model.joblib')\n",
        "print(\"\\nVoiceprint verification model saved as 'voiceprint_verification_model.joblib'\")\n"
      ],
      "metadata": {
        "id": "IpQKB4zYuhTa",
        "outputId": "109b36cf-607a-4622-e086-5763682ce892",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Voiceprint Verification Model Performance:\n",
            "Accuracy: 1.0000\n",
            "F1 Score (macro): 1.0000\n",
            "Log Loss: 0.3884\n",
            "\n",
            "Voiceprint verification model saved as 'voiceprint_verification_model.joblib'\n"
          ]
        }
      ]
    }
  ]
}