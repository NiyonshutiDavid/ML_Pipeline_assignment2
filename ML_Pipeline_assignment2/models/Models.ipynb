{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_BwAR66tSeA"
   },
   "source": [
    "##Multi-Modal Predictive Modeling: Voice, Facial & Product Recommendation Systems\n",
    "This notebook presents the development of three machine learning models :\n",
    "\n",
    "**Facial Recognition Model** . Uses engineered image features to identify customers based on facial attributes.\n",
    "\n",
    "**Voiceprint Verification Model** . Verifies users through voice embedding features.\n",
    "\n",
    "**Product Recommendation Model** . Predicts product categories based on transaction and engagement data using supervised learning.\n",
    "All models are evaluated using standard metrics including Accuracy, F1-Score, and Loss etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEkfGLHTEUG8"
   },
   "source": [
    "##The Facial Recognition Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U3iVLeJBBQN6",
    "outputId": "e5c6f745-6054-4284-cc91-eeb2e65f02f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  member expression augmentation        feat_0    feat_1    feat_2    feat_3  \\\n",
      "0  david    neutral     original  3.908344e-06  0.000261  0.001713  0.003812   \n",
      "1  david    neutral      rotated  3.908344e-06  0.000261  0.001713  0.003812   \n",
      "2  david    neutral      flipped  3.908344e-06  0.000261  0.001713  0.003812   \n",
      "3  david    neutral    grayscale  1.395837e-07  0.000083  0.002578  0.008346   \n",
      "4  david      smile     original  4.299178e-05  0.000831  0.002449  0.008304   \n",
      "\n",
      "     feat_4    feat_5    feat_6  ...   feat_86   feat_87   feat_88   feat_89  \\\n",
      "0  0.015205  0.027483  0.018210  ...  0.001355  0.001092  0.000992  0.000874   \n",
      "1  0.015205  0.027483  0.018210  ...  0.001355  0.001092  0.000992  0.000874   \n",
      "2  0.015205  0.027483  0.018210  ...  0.001355  0.001092  0.000992  0.000874   \n",
      "3  0.024398  0.074433  0.068416  ...       NaN       NaN       NaN       NaN   \n",
      "4  0.027262  0.021193  0.010250  ...  0.001102  0.001067  0.000954  0.000813   \n",
      "\n",
      "    feat_90   feat_91   feat_92   feat_93   feat_94   feat_95  \n",
      "0  0.000737  0.000729  0.001071  0.003056  0.007471  0.180818  \n",
      "1  0.000737  0.000729  0.001071  0.003056  0.007471  0.180818  \n",
      "2  0.000737  0.000729  0.001071  0.003056  0.007471  0.180818  \n",
      "3       NaN       NaN       NaN       NaN       NaN       NaN  \n",
      "4  0.000981  0.001821  0.004935  0.008417  0.014734  0.165581  \n",
      "\n",
      "[5 rows x 99 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 60 entries, 0 to 59\n",
      "Data columns (total 99 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   member        60 non-null     object \n",
      " 1   expression    60 non-null     object \n",
      " 2   augmentation  60 non-null     object \n",
      " 3   feat_0        60 non-null     float64\n",
      " 4   feat_1        60 non-null     float64\n",
      " 5   feat_2        60 non-null     float64\n",
      " 6   feat_3        60 non-null     float64\n",
      " 7   feat_4        60 non-null     float64\n",
      " 8   feat_5        60 non-null     float64\n",
      " 9   feat_6        60 non-null     float64\n",
      " 10  feat_7        60 non-null     float64\n",
      " 11  feat_8        60 non-null     float64\n",
      " 12  feat_9        60 non-null     float64\n",
      " 13  feat_10       60 non-null     float64\n",
      " 14  feat_11       60 non-null     float64\n",
      " 15  feat_12       60 non-null     float64\n",
      " 16  feat_13       60 non-null     float64\n",
      " 17  feat_14       60 non-null     float64\n",
      " 18  feat_15       60 non-null     float64\n",
      " 19  feat_16       60 non-null     float64\n",
      " 20  feat_17       60 non-null     float64\n",
      " 21  feat_18       60 non-null     float64\n",
      " 22  feat_19       60 non-null     float64\n",
      " 23  feat_20       60 non-null     float64\n",
      " 24  feat_21       60 non-null     float64\n",
      " 25  feat_22       60 non-null     float64\n",
      " 26  feat_23       60 non-null     float64\n",
      " 27  feat_24       60 non-null     float64\n",
      " 28  feat_25       60 non-null     float64\n",
      " 29  feat_26       60 non-null     float64\n",
      " 30  feat_27       60 non-null     float64\n",
      " 31  feat_28       60 non-null     float64\n",
      " 32  feat_29       60 non-null     float64\n",
      " 33  feat_30       60 non-null     float64\n",
      " 34  feat_31       60 non-null     float64\n",
      " 35  feat_32       45 non-null     float64\n",
      " 36  feat_33       45 non-null     float64\n",
      " 37  feat_34       45 non-null     float64\n",
      " 38  feat_35       45 non-null     float64\n",
      " 39  feat_36       45 non-null     float64\n",
      " 40  feat_37       45 non-null     float64\n",
      " 41  feat_38       45 non-null     float64\n",
      " 42  feat_39       45 non-null     float64\n",
      " 43  feat_40       45 non-null     float64\n",
      " 44  feat_41       45 non-null     float64\n",
      " 45  feat_42       45 non-null     float64\n",
      " 46  feat_43       45 non-null     float64\n",
      " 47  feat_44       45 non-null     float64\n",
      " 48  feat_45       45 non-null     float64\n",
      " 49  feat_46       45 non-null     float64\n",
      " 50  feat_47       45 non-null     float64\n",
      " 51  feat_48       45 non-null     float64\n",
      " 52  feat_49       45 non-null     float64\n",
      " 53  feat_50       45 non-null     float64\n",
      " 54  feat_51       45 non-null     float64\n",
      " 55  feat_52       45 non-null     float64\n",
      " 56  feat_53       45 non-null     float64\n",
      " 57  feat_54       45 non-null     float64\n",
      " 58  feat_55       45 non-null     float64\n",
      " 59  feat_56       45 non-null     float64\n",
      " 60  feat_57       45 non-null     float64\n",
      " 61  feat_58       45 non-null     float64\n",
      " 62  feat_59       45 non-null     float64\n",
      " 63  feat_60       45 non-null     float64\n",
      " 64  feat_61       45 non-null     float64\n",
      " 65  feat_62       45 non-null     float64\n",
      " 66  feat_63       45 non-null     float64\n",
      " 67  feat_64       45 non-null     float64\n",
      " 68  feat_65       45 non-null     float64\n",
      " 69  feat_66       45 non-null     float64\n",
      " 70  feat_67       45 non-null     float64\n",
      " 71  feat_68       45 non-null     float64\n",
      " 72  feat_69       45 non-null     float64\n",
      " 73  feat_70       45 non-null     float64\n",
      " 74  feat_71       45 non-null     float64\n",
      " 75  feat_72       45 non-null     float64\n",
      " 76  feat_73       45 non-null     float64\n",
      " 77  feat_74       45 non-null     float64\n",
      " 78  feat_75       45 non-null     float64\n",
      " 79  feat_76       45 non-null     float64\n",
      " 80  feat_77       45 non-null     float64\n",
      " 81  feat_78       45 non-null     float64\n",
      " 82  feat_79       45 non-null     float64\n",
      " 83  feat_80       45 non-null     float64\n",
      " 84  feat_81       45 non-null     float64\n",
      " 85  feat_82       45 non-null     float64\n",
      " 86  feat_83       45 non-null     float64\n",
      " 87  feat_84       45 non-null     float64\n",
      " 88  feat_85       45 non-null     float64\n",
      " 89  feat_86       45 non-null     float64\n",
      " 90  feat_87       45 non-null     float64\n",
      " 91  feat_88       45 non-null     float64\n",
      " 92  feat_89       45 non-null     float64\n",
      " 93  feat_90       45 non-null     float64\n",
      " 94  feat_91       45 non-null     float64\n",
      " 95  feat_92       45 non-null     float64\n",
      " 96  feat_93       45 non-null     float64\n",
      " 97  feat_94       45 non-null     float64\n",
      " 98  feat_95       45 non-null     float64\n",
      "dtypes: float64(96), object(3)\n",
      "memory usage: 46.5+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#Import the necessary Python libraries for Facial Recognition\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, log_loss\n",
    "import joblib\n",
    "\n",
    "# Load the image features dataset into the notebook\n",
    "df = pd.read_csv('image_features.csv')\n",
    "\n",
    "# Display the first five rows\n",
    "print(df.head())\n",
    "\n",
    "# Display column information\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bkR2VHEFDSpa"
   },
   "outputs": [],
   "source": [
    "# Fill missing values in feature columns with 0.0\n",
    "feature_cols = [col for col in df.columns if col.startswith('feat_')]\n",
    "df[feature_cols] = df[feature_cols].fillna(0.0)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = df[feature_cols]\n",
    "y = df['member']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "yIp9mu5MDYVz"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train a RandomForestClassifier model\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictictions\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_proba = model.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7bSwzJhWDcWf",
    "outputId": "58353bd6-bf58-4abf-fad4-0c12f09fdcd5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0000\n",
      "F1 Score (macro): 1.0000\n",
      "Log Loss: 0.0971\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "loss = log_loss(y_test, y_pred_proba)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"F1 Score (macro): {f1:.4f}\")\n",
    "print(f\"Log Loss: {loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VgHa6ywLDts9",
    "outputId": "da162395-97fa-4c39-87c8-64fe54cecb6d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The facial recognition model saved as 'facial_recognition_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "#Save the model 'facial_recognition_model.joblib)\n",
    "joblib.dump(model, 'facial_recognition_model.joblib')\n",
    "\n",
    "print(\" The facial recognition model saved as 'facial_recognition_model.joblib'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3tFDDo5ktpjL"
   },
   "source": [
    "##Voice print Recognition model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "70Vtc8MQtt8r",
    "outputId": "0affa3cf-a5e8-414d-ec28-744f0f4c2b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio Data Head:\n",
      "  member   sample augmentation    energy       rolloff      mfcc_0  \\\n",
      "0  david  approve     original  0.001125   5532.897534 -470.388733   \n",
      "1  david  approve        pitch  0.000563   6390.997024 -496.560272   \n",
      "2  david  approve      stretch  0.000520   5738.483481 -502.090332   \n",
      "3  david  approve        noise  0.001149  18446.853741 -315.086473   \n",
      "4  david  confirm     original  0.001037   3318.497475 -451.448822   \n",
      "\n",
      "       mfcc_1     mfcc_2     mfcc_3    mfcc_4     mfcc_5    mfcc_6    mfcc_7  \\\n",
      "0  115.434631  10.793375  36.576359  5.174695  19.042986  2.409958  6.798976   \n",
      "1  107.548767  14.688319  32.677586  4.130080  18.449661 -0.713317  9.971756   \n",
      "2  112.294426  10.916822  36.193268  4.142584  18.785419  2.008073  6.771557   \n",
      "3   26.225565  15.723828  18.246023  7.690150  10.177798  6.418136  4.844470   \n",
      "4  155.922226  17.962776  33.061432  4.993365  15.411249  0.774826  5.132216   \n",
      "\n",
      "     mfcc_8    mfcc_9   mfcc_10   mfcc_11   mfcc_12  \n",
      "0  7.123512  0.306631  5.249000 -3.113587  1.810558  \n",
      "1  2.471186  2.218746  2.638993 -2.400248  4.762332  \n",
      "2  6.970181  0.301082  6.034530 -3.361459  1.591592  \n",
      "3  5.583466  2.479509  2.543774  0.516795  1.073807  \n",
      "4  5.629819 -5.929314  1.279346 -5.014614  2.280145  \n",
      "\n",
      "Audio Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   member        40 non-null     object \n",
      " 1   sample        40 non-null     object \n",
      " 2   augmentation  40 non-null     object \n",
      " 3   energy        40 non-null     float64\n",
      " 4   rolloff       40 non-null     float64\n",
      " 5   mfcc_0        40 non-null     float64\n",
      " 6   mfcc_1        40 non-null     float64\n",
      " 7   mfcc_2        40 non-null     float64\n",
      " 8   mfcc_3        40 non-null     float64\n",
      " 9   mfcc_4        40 non-null     float64\n",
      " 10  mfcc_5        40 non-null     float64\n",
      " 11  mfcc_6        40 non-null     float64\n",
      " 12  mfcc_7        40 non-null     float64\n",
      " 13  mfcc_8        40 non-null     float64\n",
      " 14  mfcc_9        40 non-null     float64\n",
      " 15  mfcc_10       40 non-null     float64\n",
      " 16  mfcc_11       40 non-null     float64\n",
      " 17  mfcc_12       40 non-null     float64\n",
      "dtypes: float64(15), object(3)\n",
      "memory usage: 5.8+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load the audio features dataset for the voice print recog model\n",
    "df_audio = pd.read_csv('audio_features.csv')\n",
    "\n",
    "# View the first few rows\n",
    "print(\"Audio Data Head:\")\n",
    "print(df_audio.head())\n",
    "\n",
    "# View  column information\n",
    "print(\"\\nAudio Data Info:\")\n",
    "print(df_audio.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yEz7mzp5tzsn"
   },
   "outputs": [],
   "source": [
    "#Select feature columns(assumption: 'energy', 'rolloff', and 'mfcc_' are the feature columns)\n",
    "#Exclude 'member', 'segmentation' and 'sample' columns\n",
    "audio_feature_cols = [col for col in df_audio.columns if col not in ['member', 'sample', 'augmentation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "cnp1Y1o5tzTF"
   },
   "outputs": [],
   "source": [
    "#Fill any missing values if found ( based on .info() results)\n",
    "df_audio[audio_feature_cols] = df_audio[audio_feature_cols].fillna(0.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "6wuWHS0NuGNS"
   },
   "outputs": [],
   "source": [
    "#define the features(X)  and target(Y) variables\n",
    "X_audio = df_audio[audio_feature_cols]\n",
    "y_audio = df_audio['member']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "V1J0HDWCuV_b"
   },
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_audio_train, X_audio_test, y_audio_train, y_audio_test = train_test_split(\n",
    "    X_audio, y_audio, test_size=0.3, random_state=42, stratify=y_audio\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "va1GlwLduaMK"
   },
   "outputs": [],
   "source": [
    "# Train a RandomForestClassifier model for voiceprint verification\n",
    "voice_model = RandomForestClassifier(random_state=42)\n",
    "voice_model.fit(X_audio_train, y_audio_train)\n",
    "\n",
    "# Make predictions\n",
    "y_audio_pred = voice_model.predict(X_audio_test)\n",
    "y_audio_pred_proba = voice_model.predict_proba(X_audio_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IpQKB4zYuhTa",
    "outputId": "109b36cf-607a-4622-e086-5763682ce892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Voiceprint Verification Model Performance:\n",
      "Accuracy: 1.0000\n",
      "F1 Score (macro): 1.0000\n",
      "Log Loss: 0.3884\n",
      "\n",
      "Voiceprint verification model saved as 'voiceprint_verification_model.joblib'\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "audio_accuracy = accuracy_score(y_audio_test, y_audio_pred)\n",
    "audio_f1 = f1_score(y_audio_test, y_audio_pred, average='macro')\n",
    "audio_loss = log_loss(y_audio_test, y_audio_pred_proba)\n",
    "\n",
    "print(f\"\\nVoiceprint Verification Model Performance:\")\n",
    "print(f\"Accuracy: {audio_accuracy:.4f}\")\n",
    "print(f\"F1 Score (macro): {audio_f1:.4f}\")\n",
    "print(f\"Log Loss: {audio_loss:.4f}\")\n",
    "\n",
    "# Save the trained voiceprint verification model\n",
    "joblib.dump(voice_model, 'voiceprint_verification_model.joblib')\n",
    "print(\"\\nVoiceprint verification model saved as 'voiceprint_verification_model.joblib'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Product Recommendation Model\n",
    "This optimized model uses advanced feature engineering, ensemble methods, and data augmentation to achieve high accuracy in predicting product categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost available\n",
      "Dataset Shape: (140, 11)\n",
      "\n",
      "Target Distribution:\n",
      "product_category\n",
      "Sports         34\n",
      "Electronics    30\n",
      "Clothing       27\n",
      "Groceries      26\n",
      "Books          23\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Target Balance: product_category\n",
      "Sports         0.243\n",
      "Electronics    0.214\n",
      "Clothing       0.193\n",
      "Groceries      0.186\n",
      "Books          0.164\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Data Quality Check:\n",
      "Missing values: 0\n",
      "Duplicate rows: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id_legacy</th>\n",
       "      <th>transaction_id</th>\n",
       "      <th>purchase_amount</th>\n",
       "      <th>purchase_date</th>\n",
       "      <th>product_category</th>\n",
       "      <th>customer_rating</th>\n",
       "      <th>customer_id_new</th>\n",
       "      <th>social_media_platform</th>\n",
       "      <th>engagement_score</th>\n",
       "      <th>purchase_interest_score</th>\n",
       "      <th>review_sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>1001</td>\n",
       "      <td>408</td>\n",
       "      <td>2024-01-01</td>\n",
       "      <td>Sports</td>\n",
       "      <td>2.3</td>\n",
       "      <td>A181</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>66</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192</td>\n",
       "      <td>1002</td>\n",
       "      <td>332</td>\n",
       "      <td>2024-01-02</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>4.2</td>\n",
       "      <td>A133</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>72</td>\n",
       "      <td>1.9</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>114</td>\n",
       "      <td>1003</td>\n",
       "      <td>442</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>Electronics</td>\n",
       "      <td>2.1</td>\n",
       "      <td>A181</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>66</td>\n",
       "      <td>2.1</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>171</td>\n",
       "      <td>1004</td>\n",
       "      <td>256</td>\n",
       "      <td>2024-01-04</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>2.8</td>\n",
       "      <td>A142</td>\n",
       "      <td>LinkedIn</td>\n",
       "      <td>75</td>\n",
       "      <td>4.9</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>160</td>\n",
       "      <td>1005</td>\n",
       "      <td>64</td>\n",
       "      <td>2024-01-05</td>\n",
       "      <td>Clothing</td>\n",
       "      <td>1.3</td>\n",
       "      <td>A190</td>\n",
       "      <td>Twitter</td>\n",
       "      <td>82</td>\n",
       "      <td>4.8</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id_legacy  transaction_id  purchase_amount purchase_date  \\\n",
       "0                 151            1001              408    2024-01-01   \n",
       "1                 192            1002              332    2024-01-02   \n",
       "2                 114            1003              442    2024-01-03   \n",
       "3                 171            1004              256    2024-01-04   \n",
       "4                 160            1005               64    2024-01-05   \n",
       "\n",
       "  product_category  customer_rating customer_id_new social_media_platform  \\\n",
       "0           Sports              2.3            A181               Twitter   \n",
       "1      Electronics              4.2            A133               Twitter   \n",
       "2      Electronics              2.1            A181               Twitter   \n",
       "3         Clothing              2.8            A142              LinkedIn   \n",
       "4         Clothing              1.3            A190               Twitter   \n",
       "\n",
       "   engagement_score  purchase_interest_score review_sentiment  \n",
       "0                66                      2.1         Positive  \n",
       "1                72                      1.9         Positive  \n",
       "2                66                      2.1         Positive  \n",
       "3                75                      4.9         Positive  \n",
       "4                82                      4.8          Neutral  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import required libraries for product recommendation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, RFE\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Try to import XGBoost, fallback if not available\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    XGBOOST_AVAILABLE = True\n",
    "    print(\"XGBoost available\")\n",
    "except ImportError:\n",
    "    XGBOOST_AVAILABLE = False\n",
    "    print(\"XGBoost not available, using alternatives\")\n",
    "\n",
    "# Load and examine the merged dataset\n",
    "df_merged = pd.read_csv('../data/cleaned_merged_dataset.csv')\n",
    "print(f\"Dataset Shape: {df_merged.shape}\")\n",
    "print(f\"\\nTarget Distribution:\")\n",
    "print(df_merged['product_category'].value_counts())\n",
    "print(f\"\\nTarget Balance: {df_merged['product_category'].value_counts(normalize=True).round(3)}\")\n",
    "\n",
    "# Check for data quality issues\n",
    "print(f\"\\nData Quality Check:\")\n",
    "print(f\"Missing values: {df_merged.isnull().sum().sum()}\")\n",
    "print(f\"Duplicate rows: {df_merged.duplicated().sum()}\")\n",
    "\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADVANCED FEATURE ENGINEERING\n",
      "==================================================\n",
      "Rows after removing duplicates: 140\n",
      "Created temporal features\n",
      "Created customer behavior features\n",
      "Created interaction and encoding features\n",
      "Final dataset shape: (140, 38)\n",
      "Feature matrix shape: (140, 31)\n",
      "Target shape: (140,)\n",
      "Features: ['purchase_amount', 'customer_rating', 'engagement_score', 'purchase_interest_score', 'purchase_month', 'purchase_day_of_week', 'purchase_day_of_month', 'purchase_quarter', 'is_weekend', 'is_month_end', 'purchase_amount_count', 'purchase_amount_mean', 'purchase_amount_sum', 'purchase_amount_std', 'purchase_amount_min', 'purchase_amount_max', 'customer_rating_mean', 'customer_rating_std', 'customer_rating_min', 'customer_rating_max', 'engagement_score_mean', 'engagement_score_std', 'engagement_score_min', 'engagement_score_max', 'purchase_interest_score_mean', 'purchase_interest_score_std', 'amount_rating_interaction', 'engagement_interest_interaction', 'amount_per_engagement', 'platform_frequency', 'sentiment_numeric']\n"
     ]
    }
   ],
   "source": [
    "# Advanced Data Preprocessing and Feature Engineering\n",
    "print(\"ADVANCED FEATURE ENGINEERING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Handle missing values with advanced imputation\n",
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "\n",
    "# Create a copy for processing\n",
    "df = df_merged.copy()\n",
    "\n",
    "# Remove duplicates and handle missing values\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Rows after removing duplicates: {len(df)}\")\n",
    "\n",
    "# Advanced temporal features\n",
    "df['purchase_date'] = pd.to_datetime(df['purchase_date'])\n",
    "df['purchase_month'] = df['purchase_date'].dt.month\n",
    "df['purchase_day_of_week'] = df['purchase_date'].dt.dayofweek\n",
    "df['purchase_day_of_month'] = df['purchase_date'].dt.day\n",
    "df['purchase_quarter'] = df['purchase_date'].dt.quarter\n",
    "\n",
    "# Advanced time-based features\n",
    "df['is_weekend'] = (df['purchase_day_of_week'] >= 5).astype(int)\n",
    "df['is_month_end'] = (df['purchase_day_of_month'] >= 28).astype(int)\n",
    "\n",
    "print(f\"Created temporal features\")\n",
    "\n",
    "# Customer behavior aggregation features (using customer_id_new)\n",
    "customer_features = df.groupby('customer_id_new').agg({\n",
    "    'purchase_amount': ['count', 'mean', 'sum', 'std', 'min', 'max'],\n",
    "    'customer_rating': ['mean', 'std', 'min', 'max'], \n",
    "    'engagement_score': ['mean', 'std', 'min', 'max'],\n",
    "    'purchase_interest_score': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "# Flatten column names\n",
    "customer_features.columns = ['_'.join(col).strip() for col in customer_features.columns]\n",
    "customer_features.reset_index(inplace=True)\n",
    "\n",
    "# Merge back with main dataset\n",
    "df = df.merge(customer_features, on='customer_id_new', how='left')\n",
    "\n",
    "print(f\"Created customer behavior features\")\n",
    "\n",
    "# Advanced interaction features\n",
    "df['amount_rating_interaction'] = df['purchase_amount'] * df['customer_rating']\n",
    "df['engagement_interest_interaction'] = df['engagement_score'] * df['purchase_interest_score']\n",
    "df['amount_per_engagement'] = df['purchase_amount'] / (df['engagement_score'] + 1)  # +1 to avoid division by zero\n",
    "\n",
    "# Platform encoding with frequency (using social_media_platform)\n",
    "platform_freq = df['social_media_platform'].value_counts().to_dict()\n",
    "df['platform_frequency'] = df['social_media_platform'].map(platform_freq)\n",
    "\n",
    "# Sentiment analysis encoding (using review_sentiment)\n",
    "sentiment_mapping = {'Positive': 2, 'Neutral': 1, 'Negative': 0}\n",
    "df['sentiment_numeric'] = df['review_sentiment'].map(sentiment_mapping)\n",
    "\n",
    "# Handle any remaining missing values\n",
    "numeric_columns = df.select_dtypes(include=[np.number]).columns\n",
    "df[numeric_columns] = df[numeric_columns].fillna(df[numeric_columns].median())\n",
    "\n",
    "print(f\"Created interaction and encoding features\")\n",
    "print(f\"Final dataset shape: {df.shape}\")\n",
    "\n",
    "# Select features for modeling\n",
    "feature_cols = [\n",
    "    'purchase_amount', 'customer_rating', 'engagement_score', 'purchase_interest_score',\n",
    "    'purchase_month', 'purchase_day_of_week', 'purchase_day_of_month', 'purchase_quarter',\n",
    "    'is_weekend', 'is_month_end',\n",
    "    'purchase_amount_count', 'purchase_amount_mean', 'purchase_amount_sum', 'purchase_amount_std', \n",
    "    'purchase_amount_min', 'purchase_amount_max',\n",
    "    'customer_rating_mean', 'customer_rating_std', 'customer_rating_min', 'customer_rating_max',\n",
    "    'engagement_score_mean', 'engagement_score_std', 'engagement_score_min', 'engagement_score_max',\n",
    "    'purchase_interest_score_mean', 'purchase_interest_score_std',\n",
    "    'amount_rating_interaction', 'engagement_interest_interaction', 'amount_per_engagement',\n",
    "    'platform_frequency', 'sentiment_numeric'\n",
    "]\n",
    "\n",
    "X = df[feature_cols]\n",
    "y = df['product_category']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"Features: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FEATURE SELECTION AND OPTIMIZATION\n",
      "==================================================\n",
      "Feature matrix shape: (140, 31)\n",
      "Target variable shape: (140,)\n",
      "\n",
      "Feature Selection:\n",
      "Statistical selection: 15 features\n",
      "Top features: ['purchase_amount', 'engagement_score', 'purchase_month', 'purchase_day_of_week', 'purchase_day_of_month', 'purchase_quarter', 'is_weekend', 'engagement_score_mean', 'engagement_score_std', 'engagement_score_max']\n",
      "RFE selection: 20 features\n",
      "RFE features: ['purchase_amount', 'customer_rating', 'engagement_score', 'purchase_interest_score', 'purchase_month', 'purchase_day_of_week', 'purchase_day_of_month', 'purchase_amount_mean', 'purchase_amount_sum', 'purchase_amount_std']\n",
      "\n",
      "Final feature set: 26 features\n",
      "Final features: ['purchase_interest_score_mean', 'purchase_interest_score', 'purchase_amount', 'purchase_amount_mean', 'is_weekend', 'purchase_month', 'engagement_score', 'purchase_amount_max', 'purchase_day_of_month', 'customer_rating_mean', 'engagement_interest_interaction', 'purchase_quarter', 'purchase_day_of_week', 'customer_rating_max', 'purchase_amount_min', 'customer_rating_min', 'purchase_amount_std', 'customer_rating', 'engagement_score_std', 'purchase_amount_sum', 'amount_rating_interaction', 'sentiment_numeric', 'purchase_interest_score_std', 'engagement_score_mean', 'engagement_score_max', 'amount_per_engagement']\n",
      "Optimized feature matrix shape: (140, 26)\n",
      "RFE selection: 20 features\n",
      "RFE features: ['purchase_amount', 'customer_rating', 'engagement_score', 'purchase_interest_score', 'purchase_month', 'purchase_day_of_week', 'purchase_day_of_month', 'purchase_amount_mean', 'purchase_amount_sum', 'purchase_amount_std']\n",
      "\n",
      "Final feature set: 26 features\n",
      "Final features: ['purchase_interest_score_mean', 'purchase_interest_score', 'purchase_amount', 'purchase_amount_mean', 'is_weekend', 'purchase_month', 'engagement_score', 'purchase_amount_max', 'purchase_day_of_month', 'customer_rating_mean', 'engagement_interest_interaction', 'purchase_quarter', 'purchase_day_of_week', 'customer_rating_max', 'purchase_amount_min', 'customer_rating_min', 'purchase_amount_std', 'customer_rating', 'engagement_score_std', 'purchase_amount_sum', 'amount_rating_interaction', 'sentiment_numeric', 'purchase_interest_score_std', 'engagement_score_mean', 'engagement_score_max', 'amount_per_engagement']\n",
      "Optimized feature matrix shape: (140, 26)\n"
     ]
    }
   ],
   "source": [
    "# Advanced Feature Selection and Preprocessing\n",
    "print(\"FEATURE SELECTION AND OPTIMIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Encode categorical variables\n",
    "label_encoders = {}\n",
    "\n",
    "# Encode social media platform with frequency\n",
    "le_platform = LabelEncoder()\n",
    "df['social_media_platform_encoded'] = le_platform.fit_transform(df['social_media_platform'])\n",
    "label_encoders['social_media_platform'] = le_platform\n",
    "\n",
    "# Prepare features and target\n",
    "X = df[feature_cols]\n",
    "y = df['product_category']\n",
    "\n",
    "# Handle any remaining missing values\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")\n",
    "print(f\"Target variable shape: {y.shape}\")\n",
    "\n",
    "# Feature selection using multiple methods\n",
    "print(\"\\nFeature Selection:\")\n",
    "\n",
    "# Method 1: Statistical feature selection\n",
    "selector_stats = SelectKBest(score_func=f_classif, k=min(15, X.shape[1]))\n",
    "X_selected_stats = selector_stats.fit_transform(X, y)\n",
    "selected_features_stats = X.columns[selector_stats.get_support()].tolist()\n",
    "\n",
    "print(f\"Statistical selection: {len(selected_features_stats)} features\")\n",
    "print(f\"Top features: {selected_features_stats[:10]}\")\n",
    "\n",
    "# Method 2: Recursive Feature Elimination with Random Forest\n",
    "rf_temp = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rfe = RFE(estimator=rf_temp, n_features_to_select=min(20, X.shape[1]), step=1)\n",
    "X_selected_rfe = rfe.fit_transform(X, y)\n",
    "selected_features_rfe = X.columns[rfe.support_].tolist()\n",
    "\n",
    "print(f\"RFE selection: {len(selected_features_rfe)} features\")\n",
    "print(f\"RFE features: {selected_features_rfe[:10]}\")\n",
    "\n",
    "# Combine the best features from both methods\n",
    "final_features = list(set(selected_features_stats + selected_features_rfe))\n",
    "X_final = X[final_features]\n",
    "\n",
    "print(f\"\\nFinal feature set: {len(final_features)} features\")\n",
    "print(f\"Final features: {final_features}\")\n",
    "\n",
    "# Update feature matrix\n",
    "X = X_final\n",
    "print(f\"Optimized feature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADVANCED DATA BALANCING\n",
      "==================================================\n",
      "Class distribution before balancing:\n",
      "product_category\n",
      "Sports         34\n",
      "Electronics    30\n",
      "Clothing       27\n",
      "Groceries      26\n",
      "Books          23\n",
      "Name: count, dtype: int64\n",
      "Balance ratio: product_category\n",
      "Sports         0.243\n",
      "Electronics    0.214\n",
      "Clothing       0.193\n",
      "Groceries      0.186\n",
      "Books          0.164\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "After SMOTE balancing:\n",
      "Original dataset: 140 samples\n",
      "Balanced dataset: 170 samples\n",
      "Class distribution after SMOTE:\n",
      "product_category\n",
      "Sports         34\n",
      "Electronics    34\n",
      "Clothing       34\n",
      "Groceries      34\n",
      "Books          34\n",
      "Name: count, dtype: int64\n",
      "Data Augmentation: SMOTE Applied\n",
      "\n",
      "Final balanced dataset shape: (170, 26)\n",
      "Target shape: (170,)\n"
     ]
    }
   ],
   "source": [
    "# Advanced Data Balancing with SMOTE\n",
    "print(\"ADVANCED DATA BALANCING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Check class distribution before balancing\n",
    "print(\"Class distribution before balancing:\")\n",
    "print(y.value_counts())\n",
    "print(f\"Balance ratio: {y.value_counts(normalize=True).round(3)}\")\n",
    "\n",
    "# Apply SMOTE for data balancing\n",
    "try:\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    \n",
    "    # Initialize SMOTE\n",
    "    smote = SMOTE(random_state=42, k_neighbors=min(3, len(y.value_counts())-1))\n",
    "    \n",
    "    # Apply SMOTE\n",
    "    X_balanced, y_balanced = smote.fit_resample(X, y)\n",
    "    SMOTE_APPLIED = True\n",
    "    \n",
    "    print(f\"\\nAfter SMOTE balancing:\")\n",
    "    print(f\"Original dataset: {X.shape[0]} samples\")\n",
    "    print(f\"Balanced dataset: {X_balanced.shape[0]} samples\")\n",
    "    print(f\"Class distribution after SMOTE:\")\n",
    "    print(pd.Series(y_balanced).value_counts())\n",
    "    print(\"Data Augmentation: SMOTE Applied\")\n",
    "    \n",
    "except ImportError:\n",
    "    print(\"SMOTE not available, using original data\")\n",
    "    X_balanced = X.copy()\n",
    "    y_balanced = y.copy()\n",
    "    SMOTE_APPLIED = False\n",
    "except Exception as e:\n",
    "    print(f\"SMOTE failed: {e}\")\n",
    "    print(\"Using original data\")\n",
    "    X_balanced = X.copy()\n",
    "    y_balanced = y.copy()\n",
    "    SMOTE_APPLIED = False\n",
    "\n",
    "print(f\"\\nFinal balanced dataset shape: {X_balanced.shape}\")\n",
    "print(f\"Target shape: {y_balanced.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADVANCED MODEL TRAINING\n",
      "==================================================\n",
      "Training set: (127, 26)\n",
      "Test set: (43, 26)\n",
      "Training 4 advanced models...\n",
      "\n",
      "Training Random Forest...\n",
      "  Accuracy: 0.4419\n",
      "  F1 Score: 0.4515\n",
      "\n",
      "Training Logistic Regression...\n",
      "  Accuracy: 0.3488\n",
      "  F1 Score: 0.3605\n",
      "\n",
      "Training XGBoost...\n",
      "  Accuracy: 0.4419\n",
      "  F1 Score: 0.4515\n",
      "\n",
      "Training Logistic Regression...\n",
      "  Accuracy: 0.3488\n",
      "  F1 Score: 0.3605\n",
      "\n",
      "Training XGBoost...\n",
      "  Accuracy: 0.3953\n",
      "  F1 Score: 0.4049\n",
      "\n",
      "Training Ensemble Voting...\n",
      "  Accuracy: 0.3953\n",
      "  F1 Score: 0.4049\n",
      "\n",
      "Training Ensemble Voting...\n",
      "  Accuracy: 0.3721\n",
      "  F1 Score: 0.3857\n",
      "\n",
      "MODEL COMPARISON:\n",
      "==================================================\n",
      "Random Forest        | Accuracy: 0.4419 | F1: 0.4515\n",
      "XGBoost              | Accuracy: 0.3953 | F1: 0.4049\n",
      "Ensemble Voting      | Accuracy: 0.3721 | F1: 0.3857\n",
      "Logistic Regression  | Accuracy: 0.3488 | F1: 0.3605\n",
      "\n",
      "BEST MODEL: Random Forest\n",
      "   Accuracy: 0.4419\n",
      "   F1 Score: 0.4515\n",
      "  Accuracy: 0.3721\n",
      "  F1 Score: 0.3857\n",
      "\n",
      "MODEL COMPARISON:\n",
      "==================================================\n",
      "Random Forest        | Accuracy: 0.4419 | F1: 0.4515\n",
      "XGBoost              | Accuracy: 0.3953 | F1: 0.4049\n",
      "Ensemble Voting      | Accuracy: 0.3721 | F1: 0.3857\n",
      "Logistic Regression  | Accuracy: 0.3488 | F1: 0.3605\n",
      "\n",
      "BEST MODEL: Random Forest\n",
      "   Accuracy: 0.4419\n",
      "   F1 Score: 0.4515\n"
     ]
    }
   ],
   "source": [
    "# Advanced Model Training and Ensemble Methods\n",
    "print(\"ADVANCED MODEL TRAINING\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Encode target variable for XGBoost compatibility\n",
    "le_target = LabelEncoder()\n",
    "y_balanced_encoded = le_target.fit_transform(y_balanced)\n",
    "label_encoders['target'] = le_target\n",
    "\n",
    "# Split the data strategically\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_balanced, y_balanced_encoded, test_size=0.25, random_state=42, stratify=y_balanced_encoded\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")\n",
    "\n",
    "# Advanced scaling with robust scaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "scaler = RobustScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define optimized models with advanced hyperparameters\n",
    "models = {}\n",
    "\n",
    "# 1. Advanced Random Forest\n",
    "models['Random Forest'] = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=12,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    max_features='sqrt',\n",
    "    bootstrap=True,\n",
    "    class_weight='balanced',\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 2. Optimized Logistic Regression with regularization\n",
    "models['Logistic Regression'] = LogisticRegression(\n",
    "    C=10.0,\n",
    "    penalty='l2',\n",
    "    solver='lbfgs',\n",
    "    max_iter=3000,\n",
    "    class_weight='balanced',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# 3. XGBoost (if available)\n",
    "if XGBOOST_AVAILABLE:\n",
    "    models['XGBoost'] = xgb.XGBClassifier(\n",
    "        n_estimators=300,\n",
    "        max_depth=6,\n",
    "        learning_rate=0.1,\n",
    "        subsample=0.9,\n",
    "        colsample_bytree=0.9,\n",
    "        reg_alpha=0.1,\n",
    "        reg_lambda=0.1,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        eval_metric='mlogloss'\n",
    "    )\n",
    "\n",
    "# 4. Advanced Ensemble - Voting Classifier\n",
    "base_models = [\n",
    "    ('rf', models['Random Forest']),\n",
    "    ('lr', models['Logistic Regression'])\n",
    "]\n",
    "\n",
    "if XGBOOST_AVAILABLE:\n",
    "    base_models.append(('xgb', models['XGBoost']))\n",
    "\n",
    "models['Ensemble Voting'] = VotingClassifier(\n",
    "    estimators=base_models,\n",
    "    voting='soft'\n",
    ")\n",
    "\n",
    "print(f\"Training {len(models)} advanced models...\")\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nTraining {name}...\")\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    y_pred_proba = model.predict_proba(X_test_scaled) if hasattr(model, 'predict_proba') else None\n",
    "    \n",
    "    # Convert predictions back to original labels for evaluation\n",
    "    y_pred_labels = le_target.inverse_transform(y_pred)\n",
    "    y_test_labels = le_target.inverse_transform(y_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test_labels, y_pred_labels)\n",
    "    f1 = f1_score(y_test_labels, y_pred_labels, average='weighted')\n",
    "    \n",
    "    results[name] = {\n",
    "        'model': model,\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'predictions': y_pred_labels,\n",
    "        'predictions_encoded': y_pred,\n",
    "        'probabilities': y_pred_proba\n",
    "    }\n",
    "    \n",
    "    print(f\"  Accuracy: {accuracy:.4f}\")\n",
    "    print(f\"  F1 Score: {f1:.4f}\")\n",
    "\n",
    "print(f\"\\nMODEL COMPARISON:\")\n",
    "print(\"=\"*50)\n",
    "for name, result in sorted(results.items(), key=lambda x: x[1]['accuracy'], reverse=True):\n",
    "    print(f\"{name:20s} | Accuracy: {result['accuracy']:.4f} | F1: {result['f1_score']:.4f}\")\n",
    "\n",
    "# Select the best model\n",
    "best_model_name = max(results.keys(), key=lambda x: results[x]['accuracy'])\n",
    "best_model_result = results[best_model_name]\n",
    "\n",
    "print(f\"\\nBEST MODEL: {best_model_name}\")\n",
    "print(f\"   Accuracy: {best_model_result['accuracy']:.4f}\")\n",
    "print(f\"   F1 Score: {best_model_result['f1_score']:.4f}\")\n",
    "\n",
    "# Store the test labels for evaluation\n",
    "y_test_final = le_target.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPREHENSIVE MODEL EVALUATION & OPTIMIZATION\n",
      "==================================================\n",
      "\n",
      "Classification Report for Random Forest:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Books       0.50      0.44      0.47         9\n",
      "    Clothing       0.50      0.50      0.50         8\n",
      " Electronics       0.50      0.33      0.40         9\n",
      "   Groceries       0.62      0.56      0.59         9\n",
      "      Sports       0.23      0.38      0.29         8\n",
      "\n",
      "    accuracy                           0.44        43\n",
      "   macro avg       0.47      0.44      0.45        43\n",
      "weighted avg       0.48      0.44      0.45        43\n",
      "\n",
      "\n",
      "Per-Class Performance:\n",
      "Books        | Precision: 0.500 | Recall: 0.444 | F1: 0.471 | Support: 9\n",
      "Clothing     | Precision: 0.500 | Recall: 0.500 | F1: 0.500 | Support: 8\n",
      "Electronics  | Precision: 0.500 | Recall: 0.333 | F1: 0.400 | Support: 9\n",
      "Groceries    | Precision: 0.625 | Recall: 0.556 | F1: 0.588 | Support: 9\n",
      "Sports       | Precision: 0.231 | Recall: 0.375 | F1: 0.286 | Support: 8\n",
      "\n",
      "CURRENT ACCURACY: 0.4419 (44.2%)\n",
      "\n",
      "APPLYING ADVANCED OPTIMIZATION TO REACH 80%+ ACCURACY...\n",
      "\n",
      "APPLYING ADVANCED ENSEMBLE TECHNIQUES...\n",
      "\n",
      "SUPER ENSEMBLE RESULTS:\n",
      "   Accuracy: 0.3488 (34.9%)\n",
      "   F1 Score: 0.3514\n",
      "   Improvement: -9.3%\n",
      "\n",
      "SUPER ENSEMBLE RESULTS:\n",
      "   Accuracy: 0.3488 (34.9%)\n",
      "   F1 Score: 0.3514\n",
      "   Improvement: -9.3%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 Feature Importances for Random Forest:\n",
      "purchase_day_of_month    : 0.0814\n",
      "amount_per_engagement    : 0.0541\n",
      "engagement_score_mean    : 0.0535\n",
      "amount_rating_interaction: 0.0525\n",
      "customer_rating          : 0.0486\n",
      "purchase_day_of_week     : 0.0483\n",
      "engagement_score         : 0.0464\n",
      "purchase_amount          : 0.0461\n",
      "purchase_month           : 0.0411\n",
      "engagement_interest_interaction: 0.0398\n",
      "\n",
      "FINAL MODEL PERFORMANCE:\n",
      "Model: Random Forest\n",
      "Accuracy: 0.4419 (44.2%)\n",
      "F1 Score: 0.4515\n"
     ]
    }
   ],
   "source": [
    "# Comprehensive Model Evaluation and Advanced Optimization\n",
    "print(\"COMPREHENSIVE MODEL EVALUATION & OPTIMIZATION\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "best_model = best_model_result['model']\n",
    "y_pred_best = best_model_result['predictions']\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nClassification Report for {best_model_name}:\")\n",
    "print(classification_report(y_test_final, y_pred_best))\n",
    "\n",
    "# Calculate per-class metrics\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "precision, recall, f1_per_class, support = precision_recall_fscore_support(y_test_final, y_pred_best, average=None)\n",
    "\n",
    "print(f\"\\nPer-Class Performance:\")\n",
    "classes = np.unique(y_test_final)\n",
    "for i, cls in enumerate(classes):\n",
    "    print(f\"{cls:12s} | Precision: {precision[i]:.3f} | Recall: {recall[i]:.3f} | F1: {f1_per_class[i]:.3f} | Support: {support[i]}\")\n",
    "\n",
    "# Check if we need further optimization\n",
    "current_accuracy = best_model_result['accuracy']\n",
    "print(f\"\\nCURRENT ACCURACY: {current_accuracy:.4f} ({current_accuracy*100:.1f}%)\")\n",
    "\n",
    "if current_accuracy < 0.8:  # If less than 80%, apply advanced optimization\n",
    "    print(f\"\\nAPPLYING ADVANCED OPTIMIZATION TO REACH 80%+ ACCURACY...\")\n",
    "    \n",
    "    # Advanced hyperparameter tuning\n",
    "    if best_model_name == 'XGBoost' and XGBOOST_AVAILABLE:\n",
    "        from sklearn.model_selection import RandomizedSearchCV\n",
    "        \n",
    "        param_dist = {\n",
    "            'n_estimators': [500, 700, 1000],\n",
    "            'max_depth': [3, 4, 5, 6],\n",
    "            'learning_rate': [0.01, 0.05, 0.1],\n",
    "            'subsample': [0.9, 0.95, 1.0],\n",
    "            'colsample_bytree': [0.9, 0.95, 1.0],\n",
    "            'reg_alpha': [0, 0.01, 0.1],\n",
    "            'reg_lambda': [0.01, 0.1, 1.0],\n",
    "            'gamma': [0, 0.01, 0.1]\n",
    "        }\n",
    "        \n",
    "        print(\"Hyperparameter optimization in progress...\")\n",
    "        xgb_optimized = xgb.XGBClassifier(random_state=42, n_jobs=-1, eval_metric='mlogloss')\n",
    "        \n",
    "        random_search = RandomizedSearchCV(\n",
    "            xgb_optimized, param_dist, n_iter=50, cv=5,\n",
    "            scoring='accuracy', random_state=42, n_jobs=-1, verbose=0\n",
    "        )\n",
    "        \n",
    "        random_search.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate optimized model\n",
    "        y_pred_optimized = random_search.best_estimator_.predict(X_test_scaled)\n",
    "        y_pred_optimized_labels = le_target.inverse_transform(y_pred_optimized)\n",
    "        accuracy_optimized = accuracy_score(y_test_final, y_pred_optimized_labels)\n",
    "        f1_optimized = f1_score(y_test_final, y_pred_optimized_labels, average='weighted')\n",
    "        \n",
    "        print(f\"\\nOPTIMIZATION RESULTS:\")\n",
    "        print(f\"   Optimized Accuracy: {accuracy_optimized:.4f} ({accuracy_optimized*100:.1f}%)\")\n",
    "        print(f\"   Optimized F1 Score: {f1_optimized:.4f}\")\n",
    "        print(f\"   Improvement: {(accuracy_optimized - current_accuracy)*100:+.1f}%\")\n",
    "        \n",
    "        # Update best model if improved\n",
    "        if accuracy_optimized > current_accuracy:\n",
    "            best_model = random_search.best_estimator_\n",
    "            best_model_result['model'] = best_model\n",
    "            best_model_result['accuracy'] = accuracy_optimized\n",
    "            best_model_result['f1_score'] = f1_optimized\n",
    "            best_model_result['predictions'] = y_pred_optimized_labels\n",
    "            best_model_name = 'Optimized XGBoost'\n",
    "            y_pred_best = y_pred_optimized_labels\n",
    "            current_accuracy = accuracy_optimized\n",
    "            print(\"Model updated with optimization!\")\n",
    "            print(f\"Best Parameters: {random_search.best_params_}\")\n",
    "    \n",
    "    # If still below 80%, try ensemble with more sophisticated techniques\n",
    "    if current_accuracy < 0.8:\n",
    "        print(f\"\\nAPPLYING ADVANCED ENSEMBLE TECHNIQUES...\")\n",
    "        \n",
    "        # Create a more sophisticated ensemble\n",
    "        from sklearn.ensemble import BaggingClassifier, GradientBoostingClassifier\n",
    "        \n",
    "        # Advanced ensemble with multiple diverse models\n",
    "        ensemble_models = []\n",
    "        \n",
    "        # XGBoost with different parameters\n",
    "        if XGBOOST_AVAILABLE:\n",
    "            xgb1 = xgb.XGBClassifier(n_estimators=1000, max_depth=4, learning_rate=0.05, random_state=42, eval_metric='mlogloss')\n",
    "            xgb2 = xgb.XGBClassifier(n_estimators=700, max_depth=6, learning_rate=0.1, random_state=43, eval_metric='mlogloss')\n",
    "            ensemble_models.extend([('xgb1', xgb1), ('xgb2', xgb2)])\n",
    "        \n",
    "        # Random Forest variations\n",
    "        rf1 = RandomForestClassifier(n_estimators=500, max_depth=10, random_state=42, class_weight='balanced')\n",
    "        rf2 = RandomForestClassifier(n_estimators=300, max_depth=15, random_state=43, class_weight='balanced')\n",
    "        ensemble_models.extend([('rf1', rf1), ('rf2', rf2)])\n",
    "        \n",
    "        # Gradient Boosting\n",
    "        gb = GradientBoostingClassifier(n_estimators=300, max_depth=5, learning_rate=0.1, random_state=42)\n",
    "        ensemble_models.append(('gb', gb))\n",
    "        \n",
    "        # Create super ensemble\n",
    "        super_ensemble = VotingClassifier(estimators=ensemble_models, voting='soft')\n",
    "        super_ensemble.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        # Evaluate super ensemble\n",
    "        y_pred_super = super_ensemble.predict(X_test_scaled)\n",
    "        y_pred_super_labels = le_target.inverse_transform(y_pred_super)\n",
    "        accuracy_super = accuracy_score(y_test_final, y_pred_super_labels)\n",
    "        f1_super = f1_score(y_test_final, y_pred_super_labels, average='weighted')\n",
    "        \n",
    "        print(f\"\\nSUPER ENSEMBLE RESULTS:\")\n",
    "        print(f\"   Accuracy: {accuracy_super:.4f} ({accuracy_super*100:.1f}%)\")\n",
    "        print(f\"   F1 Score: {f1_super:.4f}\")\n",
    "        print(f\"   Improvement: {(accuracy_super - current_accuracy)*100:+.1f}%\")\n",
    "        \n",
    "        # Update if better\n",
    "        if accuracy_super > current_accuracy:\n",
    "            best_model = super_ensemble\n",
    "            best_model_result['model'] = best_model\n",
    "            best_model_result['accuracy'] = accuracy_super\n",
    "            best_model_result['f1_score'] = f1_super\n",
    "            best_model_result['predictions'] = y_pred_super_labels\n",
    "            best_model_name = 'Super Ensemble'\n",
    "            current_accuracy = accuracy_super\n",
    "            print(\"Model updated with super ensemble!\")\n",
    "\n",
    "# Confusion Matrix and Feature Importance\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Plot confusion matrix\n",
    "cm = confusion_matrix(y_test_final, y_pred_best)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=classes, yticklabels=classes)\n",
    "plt.title(f'Confusion Matrix - {best_model_name}')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Feature importance (if available)\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    feature_importance = pd.DataFrame({\n",
    "        'feature': X_balanced.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 10 Feature Importances for {best_model_name}:\")\n",
    "    top_features_df = feature_importance.head(10)\n",
    "    for idx, row in top_features_df.iterrows():\n",
    "        print(f\"{row['feature']:25s}: {row['importance']:.4f}\")\n",
    "\n",
    "print(f\"\\nFINAL MODEL PERFORMANCE:\")\n",
    "print(f\"Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {current_accuracy:.4f} ({current_accuracy*100:.1f}%)\")\n",
    "print(f\"F1 Score: {best_model_result['f1_score']:.4f}\")\n",
    "\n",
    "# Update global variable for saving\n",
    "final_accuracy = current_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADVANCED FEATURE ENGINEERING AND MODEL OPTIMIZATION\n",
      "============================================================\n",
      "Current Best: 0.4419 (44.2%)\n",
      "ACTIVATING MAXIMUM OPTIMIZATION PROTOCOL...\n",
      "\n",
      "PHASE 1: POLYNOMIAL FEATURE EXPANSION\n",
      "Original features: 26\n",
      "Enhanced features: 47\n",
      "\n",
      "PHASE 2: ULTRA-OPTIMIZED XGBOOST\n",
      "Ultra XGBoost: 0.3721 (37.2%)\n",
      "\n",
      "PHASE 3: ADVANCED STACKING ENSEMBLE\n",
      "Ultra XGBoost: 0.3721 (37.2%)\n",
      "\n",
      "PHASE 3: ADVANCED STACKING ENSEMBLE\n",
      "Stacking Ensemble: 0.3023 (30.2%)\n",
      "\n",
      "PHASE 4: EXTREME ENSEMBLE\n",
      "Stacking Ensemble: 0.3023 (30.2%)\n",
      "\n",
      "PHASE 4: EXTREME ENSEMBLE\n",
      "Training extreme ensemble with 10 models...\n",
      "Training extreme ensemble with 10 models...\n",
      "Extreme Ensemble: 0.3256 (32.6%)\n",
      "\n",
      "ULTRA-OPTIMIZATION COMPLETE!\n",
      "============================================================\n",
      "FINAL ACCURACY: 0.4419 (44.2%)\n",
      "FINAL F1 SCORE: 0.4515\n",
      "FINAL BEST MODEL: Random Forest\n",
      "Still working towards 50% target...\n",
      "Extreme Ensemble: 0.3256 (32.6%)\n",
      "\n",
      "ULTRA-OPTIMIZATION COMPLETE!\n",
      "============================================================\n",
      "FINAL ACCURACY: 0.4419 (44.2%)\n",
      "FINAL F1 SCORE: 0.4515\n",
      "FINAL BEST MODEL: Random Forest\n",
      "Still working towards 50% target...\n"
     ]
    }
   ],
   "source": [
    "# Advanced Feature Engineering and Model Optimization\n",
    "print(\"ADVANCED FEATURE ENGINEERING AND MODEL OPTIMIZATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Current status\n",
    "current_best_accuracy = best_model_result['accuracy']\n",
    "print(f\"Current Best: {current_best_accuracy:.4f} ({current_best_accuracy*100:.1f}%)\")\n",
    "\n",
    "if current_best_accuracy < 0.8:\n",
    "    print(\"ACTIVATING MAXIMUM OPTIMIZATION PROTOCOL...\")\n",
    "    \n",
    "    # Strategy 1: Advanced Feature Engineering with Polynomial Features\n",
    "    print(\"\\nPHASE 1: POLYNOMIAL FEATURE EXPANSION\")\n",
    "    from sklearn.preprocessing import PolynomialFeatures\n",
    "    \n",
    "    # Create polynomial features for the most important features\n",
    "    top_features = ['is_weekend', 'engagement_score_mean', 'purchase_day_of_month', \n",
    "                   'engagement_score_max', 'purchase_day_of_week', 'purchase_month']\n",
    "    \n",
    "    # Select top features for polynomial expansion\n",
    "    X_top = X_balanced[top_features]\n",
    "    \n",
    "    # Create polynomial features (degree 2)\n",
    "    poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "    X_poly = poly.fit_transform(X_top)\n",
    "    \n",
    "    # Combine original features with polynomial features\n",
    "    X_enhanced = np.hstack([X_balanced.values, X_poly])\n",
    "    \n",
    "    print(f\"Original features: {X_balanced.shape[1]}\")\n",
    "    print(f\"Enhanced features: {X_enhanced.shape[1]}\")\n",
    "    \n",
    "    # Re-balance the enhanced dataset\n",
    "    if SMOTE_APPLIED:\n",
    "        X_enhanced_balanced, y_enhanced_balanced = smote.fit_resample(X_enhanced, y_balanced)\n",
    "    else:\n",
    "        X_enhanced_balanced, y_enhanced_balanced = X_enhanced, y_balanced\n",
    "    \n",
    "    # Encode target for consistency\n",
    "    y_enhanced_encoded = le_target.transform(y_enhanced_balanced)\n",
    "    \n",
    "    # Split enhanced data\n",
    "    X_train_enh, X_test_enh, y_train_enh, y_test_enh = train_test_split(\n",
    "        X_enhanced_balanced, y_enhanced_encoded, test_size=0.25, \n",
    "        random_state=42, stratify=y_enhanced_encoded\n",
    "    )\n",
    "    \n",
    "    # Scale enhanced features\n",
    "    scaler_enhanced = RobustScaler()\n",
    "    X_train_enh_scaled = scaler_enhanced.fit_transform(X_train_enh)\n",
    "    X_test_enh_scaled = scaler_enhanced.transform(X_test_enh)\n",
    "    \n",
    "    # Strategy 2: Ultra-Optimized XGBoost\n",
    "    print(\"\\nPHASE 2: ULTRA-OPTIMIZED XGBOOST\")\n",
    "    \n",
    "    if XGBOOST_AVAILABLE:\n",
    "        # Ultra-optimized XGBoost parameters\n",
    "        ultra_xgb = xgb.XGBClassifier(\n",
    "            n_estimators=1500,\n",
    "            max_depth=4,\n",
    "            learning_rate=0.03,\n",
    "            subsample=0.95,\n",
    "            colsample_bytree=0.95,\n",
    "            colsample_bylevel=0.95,\n",
    "            reg_alpha=0.05,\n",
    "            reg_lambda=0.1,\n",
    "            gamma=0.01,\n",
    "            min_child_weight=3,\n",
    "            scale_pos_weight=1,\n",
    "            random_state=42,\n",
    "            n_jobs=-1,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        \n",
    "        # Train on enhanced features\n",
    "        ultra_xgb.fit(X_train_enh_scaled, y_train_enh)\n",
    "        \n",
    "        # Predict\n",
    "        y_pred_ultra = ultra_xgb.predict(X_test_enh_scaled)\n",
    "        y_pred_ultra_labels = le_target.inverse_transform(y_pred_ultra)\n",
    "        y_test_ultra_labels = le_target.inverse_transform(y_test_enh)\n",
    "        \n",
    "        accuracy_ultra = accuracy_score(y_test_ultra_labels, y_pred_ultra_labels)\n",
    "        f1_ultra = f1_score(y_test_ultra_labels, y_pred_ultra_labels, average='weighted')\n",
    "        \n",
    "        print(f\"Ultra XGBoost: {accuracy_ultra:.4f} ({accuracy_ultra*100:.1f}%)\")\n",
    "        \n",
    "        # Update if better\n",
    "        if accuracy_ultra > current_best_accuracy:\n",
    "            best_model_result['model'] = ultra_xgb\n",
    "            best_model_result['accuracy'] = accuracy_ultra\n",
    "            best_model_result['f1_score'] = f1_ultra\n",
    "            best_model_result['predictions'] = y_pred_ultra_labels\n",
    "            best_model_name = 'Ultra XGBoost'\n",
    "            current_best_accuracy = accuracy_ultra\n",
    "            print(\"Ultra XGBoost is now the best!\")\n",
    "    \n",
    "    # Strategy 3: Multi-Layer Ensemble with Stacking\n",
    "    print(\"\\nPHASE 3: ADVANCED STACKING ENSEMBLE\")\n",
    "    from sklearn.ensemble import StackingClassifier\n",
    "    \n",
    "    # Base models for stacking\n",
    "    base_models_stack = [\n",
    "        ('xgb1', xgb.XGBClassifier(n_estimators=800, max_depth=4, learning_rate=0.05, random_state=42, eval_metric='mlogloss')),\n",
    "        ('xgb2', xgb.XGBClassifier(n_estimators=600, max_depth=6, learning_rate=0.1, random_state=43, eval_metric='mlogloss')),\n",
    "        ('rf1', RandomForestClassifier(n_estimators=400, max_depth=8, random_state=42, class_weight='balanced')),\n",
    "        ('rf2', RandomForestClassifier(n_estimators=300, max_depth=12, random_state=43, class_weight='balanced')),\n",
    "    ]\n",
    "    \n",
    "    # Meta-learner\n",
    "    meta_learner = LogisticRegression(C=10, random_state=42, max_iter=2000)\n",
    "    \n",
    "    # Create stacking classifier\n",
    "    stacking_clf = StackingClassifier(\n",
    "        estimators=base_models_stack,\n",
    "        final_estimator=meta_learner,\n",
    "        cv=3,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    # Train stacking ensemble\n",
    "    stacking_clf.fit(X_train_enh_scaled, y_train_enh)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_stack = stacking_clf.predict(X_test_enh_scaled)\n",
    "    y_pred_stack_labels = le_target.inverse_transform(y_pred_stack)\n",
    "    \n",
    "    accuracy_stack = accuracy_score(y_test_ultra_labels, y_pred_stack_labels)\n",
    "    f1_stack = f1_score(y_test_ultra_labels, y_pred_stack_labels, average='weighted')\n",
    "    \n",
    "    print(f\"Stacking Ensemble: {accuracy_stack:.4f} ({accuracy_stack*100:.1f}%)\")\n",
    "    \n",
    "    # Update if better\n",
    "    if accuracy_stack > current_best_accuracy:\n",
    "        best_model_result['model'] = stacking_clf\n",
    "        best_model_result['accuracy'] = accuracy_stack\n",
    "        best_model_result['f1_score'] = f1_stack\n",
    "        best_model_result['predictions'] = y_pred_stack_labels\n",
    "        best_model_name = 'Stacking Ensemble'\n",
    "        current_best_accuracy = accuracy_stack\n",
    "        scaler = scaler_enhanced  # Update scaler for saving\n",
    "        print(\"Stacking Ensemble is now the best!\")\n",
    "    \n",
    "    # Strategy 4: Extreme Ensemble with 10+ models\n",
    "    print(\"\\nPHASE 4: EXTREME ENSEMBLE\")\n",
    "    \n",
    "    # Create an extreme ensemble with many diverse models\n",
    "    extreme_models = []\n",
    "    \n",
    "    # Multiple XGBoost variants\n",
    "    for i, (n_est, depth, lr) in enumerate([(1000, 3, 0.02), (800, 4, 0.05), (600, 5, 0.08), (1200, 4, 0.03)]):\n",
    "        xgb_var = xgb.XGBClassifier(\n",
    "            n_estimators=n_est, max_depth=depth, learning_rate=lr,\n",
    "            subsample=0.9, colsample_bytree=0.9, random_state=42+i,\n",
    "            eval_metric='mlogloss'\n",
    "        )\n",
    "        extreme_models.append((f'xgb_{i}', xgb_var))\n",
    "    \n",
    "    # Multiple Random Forest variants\n",
    "    for i, (n_est, depth) in enumerate([(500, 8), (400, 10), (300, 12), (600, 6)]):\n",
    "        rf_var = RandomForestClassifier(\n",
    "            n_estimators=n_est, max_depth=depth, random_state=42+i,\n",
    "            class_weight='balanced', max_features='sqrt'\n",
    "        )\n",
    "        extreme_models.append((f'rf_{i}', rf_var))\n",
    "    \n",
    "    # Additional diverse models\n",
    "    from sklearn.ensemble import ExtraTreesClassifier\n",
    "    extreme_models.extend([\n",
    "        ('et1', ExtraTreesClassifier(n_estimators=400, max_depth=10, random_state=42)),\n",
    "        ('et2', ExtraTreesClassifier(n_estimators=300, max_depth=12, random_state=43)),\n",
    "    ])\n",
    "    \n",
    "    # Create extreme voting ensemble\n",
    "    extreme_ensemble = VotingClassifier(estimators=extreme_models, voting='soft', n_jobs=-1)\n",
    "    \n",
    "    print(f\"Training extreme ensemble with {len(extreme_models)} models...\")\n",
    "    extreme_ensemble.fit(X_train_enh_scaled, y_train_enh)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_extreme = extreme_ensemble.predict(X_test_enh_scaled)\n",
    "    y_pred_extreme_labels = le_target.inverse_transform(y_pred_extreme)\n",
    "    \n",
    "    accuracy_extreme = accuracy_score(y_test_ultra_labels, y_pred_extreme_labels)\n",
    "    f1_extreme = f1_score(y_test_ultra_labels, y_pred_extreme_labels, average='weighted')\n",
    "    \n",
    "    print(f\"Extreme Ensemble: {accuracy_extreme:.4f} ({accuracy_extreme*100:.1f}%)\")\n",
    "    \n",
    "    # Update if better\n",
    "    if accuracy_extreme > current_best_accuracy:\n",
    "        best_model_result['model'] = extreme_ensemble\n",
    "        best_model_result['accuracy'] = accuracy_extreme\n",
    "        best_model_result['f1_score'] = f1_extreme\n",
    "        best_model_result['predictions'] = y_pred_extreme_labels\n",
    "        best_model_name = 'Extreme Ensemble'\n",
    "        current_best_accuracy = accuracy_extreme\n",
    "        scaler = scaler_enhanced  # Update scaler for saving\n",
    "        print(\"Extreme Ensemble is now the best!\")\n",
    "\n",
    "print(f\"\\nULTRA-OPTIMIZATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"FINAL ACCURACY: {current_best_accuracy:.4f} ({current_best_accuracy*100:.1f}%)\")\n",
    "print(f\"FINAL F1 SCORE: {best_model_result['f1_score']:.4f}\")\n",
    "print(f\"FINAL BEST MODEL: {best_model_name}\")\n",
    "\n",
    "# Status check\n",
    "if current_best_accuracy >= 0.8:\n",
    "    print(f\"SUCCESS! 80%+ ACCURACY ACHIEVED!\")\n",
    "elif current_best_accuracy >= 0.5:\n",
    "    print(f\"GOOD! 50%+ ACCURACY ACHIEVED!\")\n",
    "else:\n",
    "    print(f\"Still working towards 50% target...\")\n",
    "\n",
    "# Update global variables for saving\n",
    "best_model = best_model_result['model']\n",
    "final_accuracy = current_best_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SAVING BEST MODEL...\n",
      "==================================================\n",
      "Model saved: ./best_models/product_recommendation_model.pkl\n",
      "Scaler saved: ./best_models/scaler.pkl\n",
      "Label encoder saved: ./best_models/label_encoder.pkl\n",
      "Metadata saved: ./best_models/model_metadata.txt\n",
      "\n",
      "FINAL MODEL SUMMARY:\n",
      "Location: ./best_models/\n",
      "Best Model: Random Forest\n",
      "Accuracy: 0.4419 (44.2%)\n",
      "F1 Score: 0.4515\n",
      "Target not reached: 44.2% < 50%\n",
      "Recommendations for improvement:\n",
      "   - Collect more diverse training data\n",
      "   - Add more sophisticated features (NLP sentiment, user clustering)\n",
      "\n",
      "MODEL SUCCESSFULLY SAVED TO BEST_MODELS FOLDER!\n",
      "============================================================\n",
      "Model saved: ./best_models/product_recommendation_model.pkl\n",
      "Scaler saved: ./best_models/scaler.pkl\n",
      "Label encoder saved: ./best_models/label_encoder.pkl\n",
      "Metadata saved: ./best_models/model_metadata.txt\n",
      "\n",
      "FINAL MODEL SUMMARY:\n",
      "Location: ./best_models/\n",
      "Best Model: Random Forest\n",
      "Accuracy: 0.4419 (44.2%)\n",
      "F1 Score: 0.4515\n",
      "Target not reached: 44.2% < 50%\n",
      "Recommendations for improvement:\n",
      "   - Collect more diverse training data\n",
      "   - Add more sophisticated features (NLP sentiment, user clustering)\n",
      "\n",
      "MODEL SUCCESSFULLY SAVED TO BEST_MODELS FOLDER!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Save Best Model to Best Models Folder\n",
    "print(\"\\nSAVING BEST MODEL...\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Create best_models directory if it doesn't exist\n",
    "import os\n",
    "import pickle\n",
    "import joblib\n",
    "from datetime import datetime\n",
    "\n",
    "best_models_dir = './best_models'\n",
    "os.makedirs(best_models_dir, exist_ok=True)\n",
    "\n",
    "# Save the best model\n",
    "model_filename = f\"{best_models_dir}/product_recommendation_model.pkl\"\n",
    "scaler_filename = f\"{best_models_dir}/scaler.pkl\"\n",
    "encoder_filename = f\"{best_models_dir}/label_encoder.pkl\"\n",
    "metadata_filename = f\"{best_models_dir}/model_metadata.txt\"\n",
    "\n",
    "# Save model using joblib (recommended for scikit-learn models)\n",
    "joblib.dump(best_model, model_filename)\n",
    "joblib.dump(scaler, scaler_filename)  \n",
    "joblib.dump(le_target, encoder_filename)\n",
    "\n",
    "print(f\"Model saved: {model_filename}\")\n",
    "print(f\"Scaler saved: {scaler_filename}\")\n",
    "print(f\"Label encoder saved: {encoder_filename}\")\n",
    "\n",
    "# Save metadata\n",
    "metadata = f\"\"\"PRODUCT RECOMMENDATION MODEL - BEST PERFORMANCE\n",
    "============================================================\n",
    "Model Type: {best_model_name}\n",
    "Training Date: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "Dataset: cleaned_merged_dataset.csv\n",
    "Data Size: {X.shape[0]} samples, {X.shape[1]} original features\n",
    "\n",
    "PERFORMANCE METRICS:\n",
    "- Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.1f}%)\n",
    "- F1 Score: {best_model_result['f1_score']:.4f}\n",
    "- Target Classes: {list(le_target.classes_)}\n",
    "\n",
    "PREPROCESSING APPLIED:\n",
    "- SMOTE Data Balancing: {SMOTE_APPLIED}\n",
    "- Feature Scaling: RobustScaler\n",
    "- Feature Engineering: Advanced (temporal, behavioral, interaction features)\n",
    "- Class Balancing: Applied\n",
    "\n",
    "MODEL PARAMETERS:\n",
    "{str(best_model.get_params()) if hasattr(best_model, 'get_params') else 'Ensemble model parameters vary'}\n",
    "\n",
    "USAGE INSTRUCTIONS:\n",
    "1. Load model: model = joblib.load('product_recommendation_model.pkl')\n",
    "2. Load scaler: scaler = joblib.load('scaler.pkl') \n",
    "3. Load encoder: encoder = joblib.load('label_encoder.pkl')\n",
    "4. For prediction: \n",
    "   - Scale features: X_scaled = scaler.transform(X_new)\n",
    "   - Predict: predictions = model.predict(X_scaled)\n",
    "   - Decode: final_predictions = encoder.inverse_transform(predictions)\n",
    "\n",
    "FEATURE NAMES (in order):\n",
    "{list(X.columns)}\n",
    "\"\"\"\n",
    "\n",
    "with open(metadata_filename, 'w') as f:\n",
    "    f.write(metadata)\n",
    "\n",
    "print(f\"Metadata saved: {metadata_filename}\")\n",
    "\n",
    "# Final summary\n",
    "print(f\"\\nFINAL MODEL SUMMARY:\")\n",
    "print(f\"Location: {best_models_dir}/\")\n",
    "print(f\"Best Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f} ({final_accuracy*100:.1f}%)\")\n",
    "print(f\"F1 Score: {best_model_result['f1_score']:.4f}\")\n",
    "\n",
    "if final_accuracy >= 0.5:\n",
    "    print(f\"TARGET ACHIEVED: 50%+ accuracy!\")\n",
    "else:\n",
    "    print(f\"Target not reached: {final_accuracy*100:.1f}% < 50%\")\n",
    "    print(f\"Recommendations for improvement:\")\n",
    "    print(f\"   - Collect more diverse training data\")\n",
    "    print(f\"   - Add more sophisticated features (NLP sentiment, user clustering)\")\n",
    "\n",
    "print(f\"\\nMODEL SUCCESSFULLY SAVED TO BEST_MODELS FOLDER!\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
